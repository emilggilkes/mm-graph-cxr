{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os, re\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read comparison ground truth annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5433, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>studyOrder</th>\n",
       "      <th>image_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>section</th>\n",
       "      <th>bbox</th>\n",
       "      <th>relation</th>\n",
       "      <th>label_name</th>\n",
       "      <th>context</th>\n",
       "      <th>categoryID</th>\n",
       "      <th>region</th>\n",
       "      <th>annot_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10020740</td>\n",
       "      <td>58116104</td>\n",
       "      <td>2</td>\n",
       "      <td>d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm</td>\n",
       "      <td>58116104|5</td>\n",
       "      <td>finalreport</td>\n",
       "      <td>left lung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>low lung volumes</td>\n",
       "      <td>yes</td>\n",
       "      <td>technicalassessment</td>\n",
       "      <td>['left lung', 'right lung']</td>\n",
       "      <td>58116104|5|left lung|1|low lung volumes</td>\n",
       "      <td>as compared to the previous radiograph, the l...</td>\n",
       "      <td>[no change]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10020740</td>\n",
       "      <td>58116104</td>\n",
       "      <td>2</td>\n",
       "      <td>d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm</td>\n",
       "      <td>58116104|5</td>\n",
       "      <td>finalreport</td>\n",
       "      <td>right lung</td>\n",
       "      <td>1.0</td>\n",
       "      <td>low lung volumes</td>\n",
       "      <td>yes</td>\n",
       "      <td>technicalassessment</td>\n",
       "      <td>['left lung', 'right lung']</td>\n",
       "      <td>58116104|5|right lung|1|low lung volumes</td>\n",
       "      <td>as compared to the previous radiograph, the l...</td>\n",
       "      <td>[no change]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10020740</td>\n",
       "      <td>58116104</td>\n",
       "      <td>2</td>\n",
       "      <td>d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm</td>\n",
       "      <td>58116104|9</td>\n",
       "      <td>finalreport</td>\n",
       "      <td>left costophrenic angle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pleural effusion</td>\n",
       "      <td>no</td>\n",
       "      <td>anatomicalfinding</td>\n",
       "      <td>['left costophrenic angle', 'left lung', 'righ...</td>\n",
       "      <td>58116104|9|left costophrenic angle|0|pleural e...</td>\n",
       "      <td>no larger pleural effusions</td>\n",
       "      <td>[no change]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10020740</td>\n",
       "      <td>58116104</td>\n",
       "      <td>2</td>\n",
       "      <td>d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm</td>\n",
       "      <td>58116104|9</td>\n",
       "      <td>finalreport</td>\n",
       "      <td>left lung</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pleural effusion</td>\n",
       "      <td>no</td>\n",
       "      <td>anatomicalfinding</td>\n",
       "      <td>['left costophrenic angle', 'left lung', 'righ...</td>\n",
       "      <td>58116104|9|left lung|0|pleural effusion</td>\n",
       "      <td>no larger pleural effusions</td>\n",
       "      <td>[no change]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10020740</td>\n",
       "      <td>58116104</td>\n",
       "      <td>2</td>\n",
       "      <td>d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm</td>\n",
       "      <td>58116104|9</td>\n",
       "      <td>finalreport</td>\n",
       "      <td>right costophrenic angle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>yes</td>\n",
       "      <td>nlp</td>\n",
       "      <td>['left costophrenic angle', 'left lung', 'righ...</td>\n",
       "      <td>58116104|9|right costophrenic angle|1|abnormal</td>\n",
       "      <td>no larger pleural effusions</td>\n",
       "      <td>[no change]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  study_id  studyOrder  \\\n",
       "0    10020740  58116104           2   \n",
       "1    10020740  58116104           2   \n",
       "2    10020740  58116104           2   \n",
       "3    10020740  58116104           2   \n",
       "4    10020740  58116104           2   \n",
       "\n",
       "                                           image_id      row_id      section  \\\n",
       "0  d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm  58116104|5  finalreport   \n",
       "1  d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm  58116104|5  finalreport   \n",
       "2  d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm  58116104|9  finalreport   \n",
       "3  d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm  58116104|9  finalreport   \n",
       "4  d3dbb519-1ea6cf3c-bb4c1fd8-79bb117a-1dc3869f.dcm  58116104|9  finalreport   \n",
       "\n",
       "                       bbox  relation        label_name context  \\\n",
       "0                 left lung       1.0  low lung volumes     yes   \n",
       "1                right lung       1.0  low lung volumes     yes   \n",
       "2   left costophrenic angle       0.0  pleural effusion      no   \n",
       "3                 left lung       0.0  pleural effusion      no   \n",
       "4  right costophrenic angle       1.0          abnormal     yes   \n",
       "\n",
       "            categoryID                                             region  \\\n",
       "0  technicalassessment                        ['left lung', 'right lung']   \n",
       "1  technicalassessment                        ['left lung', 'right lung']   \n",
       "2    anatomicalfinding  ['left costophrenic angle', 'left lung', 'righ...   \n",
       "3    anatomicalfinding  ['left costophrenic angle', 'left lung', 'righ...   \n",
       "4                  nlp  ['left costophrenic angle', 'left lung', 'righ...   \n",
       "\n",
       "                                            annot_id  \\\n",
       "0            58116104|5|left lung|1|low lung volumes   \n",
       "1           58116104|5|right lung|1|low lung volumes   \n",
       "2  58116104|9|left costophrenic angle|0|pleural e...   \n",
       "3            58116104|9|left lung|0|pleural effusion   \n",
       "4     58116104|9|right costophrenic angle|1|abnormal   \n",
       "\n",
       "                                            sentence   comparison  \n",
       "0   as compared to the previous radiograph, the l...  [no change]  \n",
       "1   as compared to the previous radiograph, the l...  [no change]  \n",
       "2                       no larger pleural effusions   [no change]  \n",
       "3                       no larger pleural effusions   [no change]  \n",
       "4                       no larger pleural effusions   [no change]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = pd.read_csv('../gold_dataset/gold_comparison_relations_500pts_500studies2nd.txt',sep='\\t')\n",
    "comp['comparison'] = [sorted(list(set(ast.literal_eval(x)))) for x in comp['comparison']]\n",
    "# comp['bbox'] = ['' if str(x) =='nan' else x for x in comp['bbox']]\n",
    "# comp['region'] = comp.groupby(['image_id','row_id'])['bbox'].transform(lambda x: '&&'.join(x))\n",
    "# comp['region'] = [sorted(list(set(x.strip('&&').split('&&')))) for x in comp['region']]\n",
    "print(comp.shape)\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second report study for the same 500 patients were annotated for comparison descriptions\n",
      "Number of unique report studies with any comparison descriptions: 342\n",
      "From number of unique patients with any comparison descriptions: 342\n"
     ]
    }
   ],
   "source": [
    "print('The second report study for the same 500 patients were annotated for comparison descriptions')\n",
    "print('Number of unique report studies with any comparison descriptions:',len(set(comp.study_id)))\n",
    "print('From number of unique patients with any comparison descriptions:',len(set(comp.patient_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638\n",
      "(5156, 15)\n",
      "Number of unique report studies with localized comparison relation descriptions: 290\n",
      "From number of unique patients with localized comparison relation descriptions: 290\n"
     ]
    }
   ],
   "source": [
    "# Some of the comparison descriptions were non-specific and/or cannot be localized to an anatomical location even manually\n",
    "# Excluding these, there remains:\n",
    "comp = comp[(~comp.bbox.isnull())&(~comp.label_name.isnull())].reset_index(drop=True).copy()\n",
    "print(len(set(comp.row_id)))\n",
    "print(comp.shape)\n",
    "print('Number of unique report studies with localized comparison relation descriptions:',len(set(comp.study_id)))\n",
    "print('From number of unique patients with localized comparison relation descriptions:',len(set(comp.patient_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all second studies for the 500 patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patients: 500\n",
      "Number of unique studies: 1000\n",
      "Number of second exam images 500\n"
     ]
    }
   ],
   "source": [
    "# Read in the file with all the raw information for the gold standard dataset\n",
    "gold = pd.read_csv('../gold_dataset/gold_all_sentences_500pts_1000studies.txt',sep='\\t')\n",
    "print('Number of unique patients:',len(set(gold.patient_id)))\n",
    "print('Number of unique studies:',len(set(gold.study_id)))\n",
    "\n",
    "# second CXR exam for each patient to assess for comparison relation extraction\n",
    "imageIDs2 = gold[gold.StudyOrder == 2][['image_id']].drop_duplicates().image_id.tolist()\n",
    "print('Number of second exam images', len(imageIDs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read comparison relations from scene graphs to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json if path exists\n",
    "def readJSON(filepath):\n",
    "    try:\n",
    "        with open(filepath) as f:\n",
    "            data = json.load(f)\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        print('File does not exist',filepath)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "#   Tokenizing sentences\n",
    "def tokensent(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = sent.replace('\\n', ' ').replace('  ', ' ').replace(' ,', ',').replace('-', ' ') \n",
    "    sent = re.sub(r'\\[.+?\\]', '', sent)  # gets rid of the deidentification tags in mimic sentences\n",
    "    return sent\n",
    "\n",
    "\n",
    "# Get the comparison relationships between bboxes from sequential images into a table format from the scene graph json\n",
    "def SceneGraphs2ComparisonRelationsTable(imageIDs, basepath, drop_duplicates=True):\n",
    "    tab = {\n",
    "           # pattern: row_id (for subject sentence) +'_'+ study_id (for object) +'_'+ bbox synsets (UMLS id) +'_'+ element 0\n",
    "           # of object_id after split by '-'\n",
    "          'relationship_id':[], \n",
    "           # dicom_id of the subject image + '_' + bbox_name\n",
    "          'subject_id': [],\n",
    "           # dicom_id of the object image + '_' + bbox_name\n",
    "          'object_id': [],\n",
    "           # bbox_name\n",
    "          'bbox': [],\n",
    "           # comparison name\n",
    "          'comparison': [],\n",
    "           # with respect to a label, context included\n",
    "          'attribute': [],\n",
    "           # The subject sentence describing the comparison relationship\n",
    "          'sentence':[]\n",
    "          }\n",
    "    print(tab.keys())\n",
    "    \n",
    "    print('Getting the comparison relationships')\n",
    "    for i, image_id in enumerate(imageIDs):\n",
    "        if i % 1000 == 0: print('Processed comparison relations from ', i , ' scene graphs')\n",
    "        filepath = os.path.join(basepath,str(image_id.replace('.dcm','')) + '_SceneGraph.json')\n",
    "        data = readJSON(filepath)  \n",
    "        \n",
    "        comparisons = data['relationships']\n",
    "        for comp in comparisons:\n",
    "            compare = comp['relationship_names']\n",
    "            compare = [x for x in compare if x in ['comparison|yes|worsened'\n",
    "                                                   ,'comparison|yes|improved','comparison|yes|no change']]\n",
    "            compare = ';;'.join(sorted([x.split('|')[2] for x in compare]))\n",
    "            if len(compare)>0:\n",
    "                attributes = comp['attributes']\n",
    "                sent = tokensent(comp['phrase'])\n",
    "                # Get 1 row per conditioned on attribute\n",
    "                for attr in attributes:\n",
    "                    subject_id = comp['subject_id']\n",
    "                    object_id = comp['object_id']\n",
    "                    # The comparison relation should be interpreted as subject_id <has relation as compared to> object_id\n",
    "                    tab['relationship_id'].append(comp['relationship_id']) # relationship id that unique ID the comparison\n",
    "                    tab['subject_id'].append(subject_id) # The bbox from the current image (NOT the patient id here)\n",
    "                    tab['object_id'].append(object_id) # The bbox (same anatomy) from the previous image\n",
    "                    tab['bbox'].append(comp['bbox_name']) # The anatomical location described (bbox)\n",
    "                    tab['comparison'].append(compare) # The comparison relationships are in ['improved','worsened','no change']\n",
    "                    tab['attribute'].append(attr) # The finding, disease, or tech assess label that conditions the relationship\n",
    "                    tab['sentence'].append(sent) # The sentence in the current report that describes the comparison relationship\n",
    "                    \n",
    "    scene_comp = pd.DataFrame(tab).copy()\n",
    "    print(scene_comp.shape)\n",
    "    \n",
    "    scene_comp['current_image_id'] = [x.split('_')[0]+'.dcm' for x in scene_comp['subject_id']]\n",
    "    print(set(scene_comp.comparison))\n",
    "\n",
    "    # Some preprocessing -- needs to be same as that done for experiment\n",
    "    # Similar rationale as that for picking the attribute annotations\n",
    "    # There may be multiple sents per bbox-comparison-attribute relation with different context for the attribute\n",
    "    scene_comp['sent_loc'] = [float(x.split('_')[0].split('|')[-1]) for x in scene_comp['relationship_id']]\n",
    "    scene_comp['label_name'] = [x.split('|')[-1] for x in scene_comp['attribute']]\n",
    "\n",
    "    if drop_duplicates:\n",
    "        # Sort by unique subject-object-label and sent_loc (order of sentences in a report)\n",
    "        scene_comp = scene_comp.sort_values(by=['subject_id','object_id','sent_loc','bbox','label_name']).reset_index(drop=True).copy()\n",
    "        print(scene_comp.shape)\n",
    "        # keep last label context and comparison for subject-object-label combinations\n",
    "        scene_comp = scene_comp.drop_duplicates(subset=['subject_id','object_id','bbox','label_name'],keep='last').reset_index(drop=True).copy()\n",
    "        scene_comp.drop(['sent_loc','label_name'],axis=1,inplace=True)\n",
    "        print(scene_comp.shape)\n",
    "\n",
    "    # needs to be a list for evaluation analysis\n",
    "    scene_comp['comparison'] = [sorted(list(set(x.split(';;')))) for x in scene_comp['comparison']]\n",
    "    scene_comp['annot_id'] = ['|'.join([rel.split('_')[0],box,att.split('|')[1],att.split('|')[2]]) \n",
    "                              for rel, box, att in zip(scene_comp['relationship_id'],scene_comp['bbox'],scene_comp['attribute'])]\n",
    "    scene_comp['annot_id'] = [x.replace('|yes|','|1|').replace('|no|','|0|') for x in scene_comp['annot_id']]\n",
    "    \n",
    "    return scene_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: set path to the scene_graph json directory\n",
    "images_dir = '../../../subset/scene_graph/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['relationship_id', 'subject_id', 'object_id', 'bbox', 'comparison', 'attribute', 'sentence'])\n",
      "Getting the comparison relationships\n",
      "Processed comparison relations from  0  scene graphs\n",
      "(5368, 7)\n",
      "{'improved', 'no change', 'improved;;worsened', 'worsened', 'no change;;worsened', 'improved;;no change'}\n",
      "(5368, 10)\n",
      "(4157, 8)\n"
     ]
    }
   ],
   "source": [
    "# Extract comparison relations in scene graphs to a table for easier comparison against ground truth\n",
    "scene_comp = SceneGraphs2ComparisonRelationsTable(imageIDs2, images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relationship_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>comparison</th>\n",
       "      <th>attribute</th>\n",
       "      <th>sentence</th>\n",
       "      <th>current_image_id</th>\n",
       "      <th>annot_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58043799|9_53976162_C0003489_00637f42_1b190280</td>\n",
       "      <td>00637f42-a2f19a71-cd265165-0928eca9-c6d14eee_a...</td>\n",
       "      <td>1b190280-f5724ebf-d8ec76c3-cc23434f-9969aec8_a...</td>\n",
       "      <td>aortic arch</td>\n",
       "      <td>[no change]</td>\n",
       "      <td>nlp|yes|abnormal</td>\n",
       "      <td>slight rightward deviation of the trachea is t...</td>\n",
       "      <td>00637f42-a2f19a71-cd265165-0928eca9-c6d14eee.dcm</td>\n",
       "      <td>58043799|9|aortic arch|1|abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58043799|9_53976162_C0003489_00637f42_1b190280</td>\n",
       "      <td>00637f42-a2f19a71-cd265165-0928eca9-c6d14eee_a...</td>\n",
       "      <td>1b190280-f5724ebf-d8ec76c3-cc23434f-9969aec8_a...</td>\n",
       "      <td>aortic arch</td>\n",
       "      <td>[no change]</td>\n",
       "      <td>anatomicalfinding|yes|tortuous aorta</td>\n",
       "      <td>slight rightward deviation of the trachea is t...</td>\n",
       "      <td>00637f42-a2f19a71-cd265165-0928eca9-c6d14eee.dcm</td>\n",
       "      <td>58043799|9|aortic arch|1|tortuous aorta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  relationship_id  \\\n",
       "0  58043799|9_53976162_C0003489_00637f42_1b190280   \n",
       "1  58043799|9_53976162_C0003489_00637f42_1b190280   \n",
       "\n",
       "                                          subject_id  \\\n",
       "0  00637f42-a2f19a71-cd265165-0928eca9-c6d14eee_a...   \n",
       "1  00637f42-a2f19a71-cd265165-0928eca9-c6d14eee_a...   \n",
       "\n",
       "                                           object_id         bbox  \\\n",
       "0  1b190280-f5724ebf-d8ec76c3-cc23434f-9969aec8_a...  aortic arch   \n",
       "1  1b190280-f5724ebf-d8ec76c3-cc23434f-9969aec8_a...  aortic arch   \n",
       "\n",
       "    comparison                             attribute  \\\n",
       "0  [no change]                      nlp|yes|abnormal   \n",
       "1  [no change]  anatomicalfinding|yes|tortuous aorta   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  slight rightward deviation of the trachea is t...   \n",
       "1  slight rightward deviation of the trachea is t...   \n",
       "\n",
       "                                   current_image_id  \\\n",
       "0  00637f42-a2f19a71-cd265165-0928eca9-c6d14eee.dcm   \n",
       "1  00637f42-a2f19a71-cd265165-0928eca9-c6d14eee.dcm   \n",
       "\n",
       "                                  annot_id  \n",
       "0        58043799|9|aortic arch|1|abnormal  \n",
       "1  58043799|9|aortic arch|1|tortuous aorta  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_comp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get comparison annotation IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp['com_annot_id'] = ['|'.join([annotID,'&'.join(sorted(list(set(cp))))]) for annotID, cp in zip(comp['annot_id'],comp['comparison'])]\n",
    "scene_comp['com_annot_id'] = ['|'.join([annotID,'&'.join(sorted(list(set(cp))))]) for annotID, cp in zip(scene_comp['annot_id'],scene_comp['comparison'])]\n",
    "\n",
    "# # pattern: 0 study_id | 1 sent_loc | 2 bbox | 3 context | 4 attribute | 5 comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence level comparison performance, attribute sensitive:\n",
      "True positive sent level: 3040\n",
      "False negative sent level: 2114\n",
      "False positive sent level: 620\n",
      "Number of relations: 5154\n",
      "Precision sent level: 0.8306010928961749\n",
      "Recall sent level: 0.5898331393092744\n",
      "f1-score sent level: 0.6898116632629907\n"
     ]
    }
   ],
   "source": [
    "# Sentence level comparison performance\n",
    "print('Sentence level comparison performance, attribute sensitive:')\n",
    "compgt = set(comp['com_annot_id'].tolist())\n",
    "compscene = set(scene_comp['com_annot_id'].tolist())\n",
    "truepos = compgt.intersection(compscene)\n",
    "falseneg = compgt.difference(compscene)\n",
    "falsepos = compscene.difference(compgt)\n",
    "precision = len(truepos)/(len(truepos)+len(falsepos))\n",
    "recall = len(truepos)/(len(truepos)+len(falseneg))\n",
    "print('True positive sent level:', len(truepos))\n",
    "print('False negative sent level:', len(falseneg))\n",
    "print('False positive sent level:', len(falsepos))\n",
    "print('Number of relations:', len(truepos) + len(falseneg))\n",
    "print('Precision sent level:', precision)\n",
    "print('Recall sent level:', recall)\n",
    "print('f1-score sent level:', 2*precision*recall/(precision+recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparison relation: improved\n",
      "True positive sent level: 484\n",
      "False negative sent level: 411\n",
      "False positive sent level: 179\n",
      "Precision sent level: 0.7300150829562594\n",
      "Recall sent level: 0.5407821229050279\n",
      "f1-score sent level: 0.6213093709884466\n",
      "\n",
      "For comparison relation: worsened\n",
      "True positive sent level: 943\n",
      "False negative sent level: 1073\n",
      "False positive sent level: 183\n",
      "Precision sent level: 0.8374777975133215\n",
      "Recall sent level: 0.4677579365079365\n",
      "f1-score sent level: 0.6002546148949713\n",
      "\n",
      "For comparison relation: no change\n",
      "True positive sent level: 1619\n",
      "False negative sent level: 670\n",
      "False positive sent level: 399\n",
      "Precision sent level: 0.8022794846382557\n",
      "Recall sent level: 0.7072957623416339\n",
      "f1-score sent level: 0.7517993963315532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For different comparison relations - sentence level, attribute sensitive\n",
    "for rel in ['improved','worsened','no change']:\n",
    "    gt = comp[comp['com_annot_id'].str.contains(rel)].copy()\n",
    "    pred = scene_comp[scene_comp['com_annot_id'].str.contains(rel)].copy()\n",
    "    compgt = set(gt['com_annot_id'].tolist())\n",
    "    compscene = set(pred['com_annot_id'].tolist())\n",
    "    truepos = compgt.intersection(compscene)\n",
    "    falseneg = compgt.difference(compscene)\n",
    "    falsepos = compscene.difference(compgt)\n",
    "    precision = len(truepos)/(len(truepos)+len(falsepos))\n",
    "    recall = len(truepos)/(len(truepos)+len(falseneg))\n",
    "    print('For comparison relation:', rel)\n",
    "    print('True positive sent level:', len(truepos))\n",
    "    print('False negative sent level:', len(falseneg))\n",
    "    print('False positive sent level:', len(falsepos))\n",
    "    print('Precision sent level:', precision)\n",
    "    print('Recall sent level:', recall)\n",
    "    print('f1-score sent level:', 2*precision*recall/(precision+recall))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence level comparison performance, attribute blind:\n",
      "True positive sent level: 1184\n",
      "False negative sent level: 603\n",
      "False positive sent level: 199\n",
      "Number of relations: 1787\n",
      "Precision sent level: 0.8561099060014461\n",
      "Recall sent level: 0.6625629546726357\n",
      "f1-score sent level: 0.7470031545741325\n"
     ]
    }
   ],
   "source": [
    "# Sentence level comparison performance\n",
    "print('Sentence level comparison performance, attribute blind:')\n",
    "compgt = set(['|'.join([c.split('|')[0],c.split('|')[1],c.split('|')[2],c.split('|')[5]]) for c in comp['com_annot_id']])\n",
    "compscene = set(['|'.join([c.split('|')[0],c.split('|')[1],c.split('|')[2],c.split('|')[5]]) for c in scene_comp['com_annot_id']])\n",
    "\n",
    "truepos = compgt.intersection(compscene)\n",
    "falseneg = compgt.difference(compscene)\n",
    "falsepos = compscene.difference(compgt)\n",
    "\n",
    "precision = len(truepos)/(len(truepos)+len(falsepos))\n",
    "recall = len(truepos)/(len(truepos)+len(falseneg))\n",
    "print('True positive sent level:', len(truepos))\n",
    "print('False negative sent level:', len(falseneg))\n",
    "print('False positive sent level:', len(falsepos))\n",
    "print('Number of relations:', len(truepos) + len(falseneg))\n",
    "print('Precision sent level:', precision)\n",
    "print('Recall sent level:', recall)\n",
    "print('f1-score sent level:', 2*precision*recall/(precision+recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparison relation: improved\n",
      "True positive sent level: 209\n",
      "False negative sent level: 61\n",
      "False positive sent level: 52\n",
      "Precision sent level: 0.8007662835249042\n",
      "Recall sent level: 0.774074074074074\n",
      "f1-score sent level: 0.7871939736346515\n",
      "\n",
      "For comparison relation: worsened\n",
      "True positive sent level: 295\n",
      "False negative sent level: 148\n",
      "False positive sent level: 63\n",
      "Precision sent level: 0.8240223463687151\n",
      "Recall sent level: 0.6659142212189616\n",
      "f1-score sent level: 0.7365792759051187\n",
      "\n",
      "For comparison relation: no change\n",
      "True positive sent level: 593\n",
      "False negative sent level: 95\n",
      "False positive sent level: 101\n",
      "Precision sent level: 0.8544668587896254\n",
      "Recall sent level: 0.8619186046511628\n",
      "f1-score sent level: 0.858176555716353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For different comparison relations - sentence level, attribute blind\n",
    "for rel in ['improved','worsened','no change']:\n",
    "    gt = comp[comp['com_annot_id'].str.contains(rel)].copy()\n",
    "    pred = scene_comp[scene_comp['com_annot_id'].str.contains(rel)].copy()\n",
    "    compgt = set(['|'.join([c.split('|')[0],c.split('|')[2],c.split('|')[5]]) for c in gt['com_annot_id']])\n",
    "    compscene = set(['|'.join([c.split('|')[0],c.split('|')[2],c.split('|')[5]]) for c in pred['com_annot_id']])\n",
    "    truepos = compgt.intersection(compscene)\n",
    "    falseneg = compgt.difference(compscene)\n",
    "    falsepos = compscene.difference(compgt)\n",
    "    precision = len(truepos)/(len(truepos)+len(falsepos))\n",
    "    recall = len(truepos)/(len(truepos)+len(falseneg))\n",
    "    print('For comparison relation:', rel)\n",
    "    print('True positive sent level:', len(truepos))\n",
    "    print('False negative sent level:', len(falseneg))\n",
    "    print('False positive sent level:', len(falsepos))\n",
    "    print('Precision sent level:', precision)\n",
    "    print('Recall sent level:', recall)\n",
    "    print('f1-score sent level:', 2*precision*recall/(precision+recall))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5156, 17)\n",
      "(3995, 16)\n",
      "(4157, 12)\n",
      "(3660, 11)\n"
     ]
    }
   ],
   "source": [
    "## Rolling annotations to study level\n",
    "\n",
    "# There may be multiple sents per bbox-comparison-attribute relation with different context for the attribute\n",
    "comp2 = comp.copy()\n",
    "comp2['sent_loc'] = [float(x.split('_')[0].split('|')[-1]) for x in comp2['row_id']]\n",
    "# Sort by unique subject-object-label and sent_loc (order of sentences in a report)\n",
    "comp2 = comp2.sort_values(by=['image_id','sent_loc','bbox','label_name']).reset_index(drop=True).copy()\n",
    "print(comp2.shape)\n",
    "# keep last label context and comparison for subject-object-label combinations\n",
    "comp2 = comp2.drop_duplicates(subset=['image_id','bbox','label_name'],keep='last').reset_index(drop=True).copy()\n",
    "comp2.drop(['sent_loc'],axis=1,inplace=True)\n",
    "print(comp2.shape)\n",
    "\n",
    "# Same for automatically extracted relations\n",
    "scene_comp2 = scene_comp.copy()\n",
    "scene_comp2['label_name'] = [x.split('|')[-1] for x in scene_comp2['attribute']]\n",
    "scene_comp2['sent_loc'] = [float(x.split('_')[0].split('|')[-1]) for x in scene_comp2['relationship_id']]\n",
    "# Sort by unique subject-object-label and sent_loc (order of sentences in a report)\n",
    "scene_comp2 = scene_comp2.sort_values(by=['subject_id','sent_loc','bbox','label_name']).reset_index(drop=True).copy()\n",
    "print(scene_comp2.shape)\n",
    "# keep last label context and comparison for subject-object-label combinations\n",
    "scene_comp2 = scene_comp2.drop_duplicates(subset=['subject_id','bbox','label_name'],keep='last').reset_index(drop=True).copy()\n",
    "scene_comp2.drop(['sent_loc'],axis=1,inplace=True)\n",
    "print(scene_comp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report level comparison performance, attribute sensitive:\n",
      "True positive report level: 3044\n",
      "False negative report level: 949\n",
      "False positive report level: 616\n",
      "Number of relations: 3993\n",
      "Precision report level: 0.8316939890710382\n",
      "Recall report level: 0.7623340846481342\n",
      "f1-score report level: 0.7955050307069124\n"
     ]
    }
   ],
   "source": [
    "# Report level comparison performance\n",
    "print('Report level comparison performance, attribute sensitive:')\n",
    "compgt = set(['|'.join([c.split('|')[0],'|'.join(c.split('|')[2:])]) for c in comp2['com_annot_id']])\n",
    "compscene = set(['|'.join([c.split('|')[0],'|'.join(c.split('|')[2:])]) for c in scene_comp2['com_annot_id']])\n",
    "\n",
    "truepos = compgt.intersection(compscene)\n",
    "falseneg = compgt.difference(compscene)\n",
    "falsepos = compscene.difference(compgt)\n",
    "\n",
    "precision = len(truepos)/(len(truepos)+len(falsepos))\n",
    "recall = len(truepos)/(len(truepos)+len(falseneg))\n",
    "print('True positive report level:', len(truepos))\n",
    "print('False negative report level:', len(falseneg))\n",
    "print('False positive report level:', len(falsepos))\n",
    "print('Number of relations:', len(truepos) + len(falseneg))\n",
    "print('Precision report level:', precision)\n",
    "print('Recall report level:', recall)\n",
    "print('f1-score report level:', 2*precision*recall/(precision+recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparison relation: improved\n",
      "True positive report level: 482\n",
      "False negative report level: 172\n",
      "False positive report level: 181\n",
      "Precision report level: 0.726998491704374\n",
      "Recall report level: 0.7370030581039755\n",
      "f1-score report level: 0.7319665907365223\n",
      "\n",
      "For comparison relation: worsened\n",
      "True positive report level: 943\n",
      "False negative report level: 528\n",
      "False positive report level: 183\n",
      "Precision report level: 0.8374777975133215\n",
      "Recall report level: 0.6410605030591434\n",
      "f1-score report level: 0.7262225644974971\n",
      "\n",
      "For comparison relation: no change\n",
      "True positive report level: 1625\n",
      "False negative report level: 275\n",
      "False positive report level: 393\n",
      "Precision report level: 0.8052527254707631\n",
      "Recall report level: 0.8552631578947368\n",
      "f1-score report level: 0.8295048494129658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For different comparison relations - report level, attribute sensitive\n",
    "for rel in ['improved','worsened','no change']:\n",
    "    gt = comp2[comp2['com_annot_id'].str.contains(rel)].copy()\n",
    "    pred = scene_comp2[scene_comp2['com_annot_id'].str.contains(rel)].copy()\n",
    "    compgt = set(['|'.join([c.split('|')[0],'|'.join(c.split('|')[2:])]) for c in gt['com_annot_id']])\n",
    "    compscene = set(['|'.join([c.split('|')[0],'|'.join(c.split('|')[2:])]) for c in pred['com_annot_id']])\n",
    "    truepos = compgt.intersection(compscene)\n",
    "    falseneg = compgt.difference(compscene)\n",
    "    falsepos = compscene.difference(compgt)\n",
    "    precision = len(truepos)/(len(truepos)+len(falsepos))\n",
    "    recall = len(truepos)/(len(truepos)+len(falseneg))\n",
    "    print('For comparison relation:', rel)\n",
    "    print('True positive report level:', len(truepos))\n",
    "    print('False negative report level:', len(falseneg))\n",
    "    print('False positive report level:', len(falsepos))\n",
    "    print('Precision report level:', precision)\n",
    "    print('Recall report level:', recall)\n",
    "    print('f1-score report level:', 2*precision*recall/(precision+recall))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report level comparison performance, attribute blind:\n",
      "True positive report level: 1086\n",
      "False negative report level: 288\n",
      "False positive report level: 179\n",
      "Number of relations: 1374\n",
      "Precision report level: 0.8584980237154151\n",
      "Recall report level: 0.7903930131004366\n",
      "f1-score report level: 0.8230390299355818\n"
     ]
    }
   ],
   "source": [
    "# Report level comparison performance\n",
    "print('Report level comparison performance, attribute blind:')\n",
    "compgt = set(['|'.join([c.split('|')[0],c.split('|')[2],c.split('|')[5]]) for c in comp2['com_annot_id']])\n",
    "compscene = set(['|'.join([c.split('|')[0],c.split('|')[2],c.split('|')[5]]) for c in scene_comp2['com_annot_id']])\n",
    "\n",
    "truepos = compgt.intersection(compscene)\n",
    "falseneg = compgt.difference(compscene)\n",
    "falsepos = compscene.difference(compgt)\n",
    "\n",
    "precision = len(truepos)/(len(truepos)+len(falsepos))\n",
    "recall = len(truepos)/(len(truepos)+len(falseneg))\n",
    "print('True positive report level:', len(truepos))\n",
    "print('False negative report level:', len(falseneg))\n",
    "print('False positive report level:', len(falsepos))\n",
    "print('Number of relations:', len(truepos) + len(falseneg))\n",
    "print('Precision report level:', precision)\n",
    "print('Recall report level:', recall)\n",
    "print('f1-score report level:', 2*precision*recall/(precision+recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparison relation: improved\n",
      "True positive report level: 205\n",
      "False negative report level: 59\n",
      "False positive report level: 56\n",
      "Precision report level: 0.7854406130268199\n",
      "Recall report level: 0.7765151515151515\n",
      "f1-score report level: 0.780952380952381\n",
      "\n",
      "For comparison relation: worsened\n",
      "True positive report level: 294\n",
      "False negative report level: 148\n",
      "False positive report level: 64\n",
      "Precision report level: 0.8212290502793296\n",
      "Recall report level: 0.665158371040724\n",
      "f1-score report level: 0.7349999999999999\n",
      "\n",
      "For comparison relation: no change\n",
      "True positive report level: 590\n",
      "False negative report level: 90\n",
      "False positive report level: 104\n",
      "Precision report level: 0.8501440922190202\n",
      "Recall report level: 0.8676470588235294\n",
      "f1-score report level: 0.8588064046579331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For different comparison relations - report level, attribute blind\n",
    "for rel in ['improved','worsened','no change']:\n",
    "    gt = comp2[comp2['com_annot_id'].str.contains(rel)].copy()\n",
    "    pred = scene_comp2[scene_comp2['com_annot_id'].str.contains(rel)].copy()\n",
    "    compgt = set(['|'.join([c.split('|')[0],c.split('|')[2],c.split('|')[5]]) for c in gt['com_annot_id']])\n",
    "    compscene = set(['|'.join([c.split('|')[0],c.split('|')[2],c.split('|')[5]]) for c in pred['com_annot_id']])\n",
    "    truepos = compgt.intersection(compscene)\n",
    "    falseneg = compgt.difference(compscene)\n",
    "    falsepos = compscene.difference(compgt)\n",
    "    precision = len(truepos)/(len(truepos)+len(falsepos))\n",
    "    recall = len(truepos)/(len(truepos)+len(falseneg))\n",
    "    print('For comparison relation:', rel)\n",
    "    print('True positive report level:', len(truepos))\n",
    "    print('False negative report level:', len(falseneg))\n",
    "    print('False positive report level:', len(falsepos))\n",
    "    print('Precision report level:', precision)\n",
    "    print('Recall report level:', recall)\n",
    "    print('f1-score report level:', 2*precision*recall/(precision+recall))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
